{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[{"file_id":"10B2s5af8INkHgIz_7XBjW3iNDbGY7ltx","timestamp":1729940260943}],"collapsed_sections":["vncDsAP0Gaoa","FJNUwmbgGyua","w6K7xa23Elo4","yQaldy8SH6Dl","mDgbUHAGgjLW","O_i_v8NEhb9l","HhfV-JJviCcP","Y3lxredqlCYt","3RnN4peoiCZX","x71ZqKXriCWQ","7hBIi_osiCS2","JlHwYmJAmNHm","35m5QtbWiB9F","PoPl-ycgm1ru","H0kj-8xxnORC","nA9Y7ga8ng1Z","PBTbrJXOngz2","u3PMJOP6ngxN","dauF4eBmngu3","bKJF3rekwFvQ","MSa1f5Uengrz","GF8Ens_Soomf","0wOQAZs5pc--","K5QZ13OEpz2H","lQ7QKXXCp7Bj","448CDAPjqfQr","KSlN3yHqYklG","t6dVpIINYklI","ijmpgYnKYklI","-JiQyfWJYklI","EM7whBJCYoAo","fge-S5ZAYoAp","85gYPyotYoAp","RoGjAbkUYoAp","4Of9eVA-YrdM","iky9q4vBYrdO","F6T5p64dYrdO","y-Ehk30pYrdP","bamQiAODYuh1","QHF8YVU7Yuh3","GwzvFGzlYuh3","qYpmQ266Yuh3","OH-pJp9IphqM","bbFf2-_FphqN","_ouA3fa0phqN","Seke61FWphqN","PIIx-8_IphqN","t27r6nlMphqO","r2jJGEOYphqO","b0JNsNcRphqO","BZR9WyysphqO","jj7wYXLtphqO","eZrbJ2SmphqO","rFu4xreNphqO","YJ55k-q6phqO","gCFgpxoyphqP","OVtJsKN_phqQ","lssrdh5qphqQ","U2RJ9gkRphqQ","1M8mcRywphqQ","tgIPom80phqQ","JMzcOPDDphqR","x-EpHcCOp1ci","X_VqEhTip1ck","8zGJKyg5p1ck","PVzmfK_Ep1ck","n3dbpmDWp1ck","ylSl6qgtp1ck","ZWILFDl5p1ck","M7G43BXep1ck","Ag9LCva-p1cl","E6MkPsBcp1cl","2cELzS2fp1cl","3MPXvC8up1cl","NC_X3p0fY2L0","UV0SzAkaZNRQ","YPEH6qLeZNRQ","q29F0dvdveiT","EXh0U9oCveiU","22aHeOlLveiV","g-ATYxFrGrvw","Yfr_Vlr8HBkt","8yEUt7NnHlrM","tEA2Xm5dHt1r","I79__PHVH19G","Ou-I18pAyIpj","fF3858GYyt-u","4_0_7-oCpUZd","hwyV_J3ipUZe","3yB-zSqbpUZe","dEUvejAfpUZe","Fd15vwWVpUZf","bn_IUdTipZyH","49K5P_iCpZyH","Nff-vKELpZyI","kLW572S8pZyI","dWbDXHzopZyI","yLjJCtPM0KBk","xiyOF9F70UgQ","7wuGOrhz0itI","id1riN9m0vUs","578E2V7j08f6","89xtkJwZ18nB","67NQN5KX2AMe","Iwf50b-R2tYG","GMQiZwjn3iu7","WVIkgGqN3qsr","XkPnILGE3zoT","Hlsf0x5436Go","mT9DMSJo4nBL","c49ITxTc407N","OeJFEK0N496M","9ExmJH0g5HBk","cJNqERVU536h","k5UmGsbsOxih","T0VqWOYE6DLQ","qBMux9mC6MCf","-oLEiFgy-5Pf","C74aWNz2AliB","2DejudWSA-a0","pEMng2IbBLp7","rAdphbQ9Bhjc","TNVZ9zx19K6k","nqoHp30x9hH9","rMDnDkt2B6du","yiiVWRdJDDil","1UUpS68QDMuG","kexQrXU-DjzY","T5CmagL3EC8N","BhH2vgX9EjGr","qjKvONjwE8ra","P1XJ9OREExlT","VFOzZv6IFROw","TIqpNgepFxVj","VfCC591jGiD4","OB4l2ZhMeS1U","ArJBuiUVfxKd","4qY1EAkEfxKe","PiV4Ypx8fxKe","TfvqoZmBfxKf","dJ2tPlVmpsJ0","JWYfwnehpsJ1","-jK_YjpMpsJ2","HAih1iBOpsJ2","zVGeBEFhpsJ2","bmKjuQ-FpsJ3","Fze-IPXLpx6K","7AN1z2sKpx6M","9PIHJqyupx6M","_-qAgymDpx6N","Z-hykwinpx6N","h_CCil-SKHpo","cBFFvTBNJzUa","HvGl1hHyA_VK","EyNgTHvd2WFk","KH5McJBi2d8v","iW_Lq9qf2h6X","-Kee-DAl2viO","gCX9965dhzqZ","gIfDvo9L0UH2"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Project Name**    -\n","\n"],"metadata":{"id":"vncDsAP0Gaoa"}},{"cell_type":"markdown","source":["##### **Project Type**    - Regression\n","##### **Contribution**    - Individual\n"],"metadata":{"id":"beRrZCGUAJYm"}},{"cell_type":"markdown","source":["# **Project Summary -**"],"metadata":{"id":"FJNUwmbgGyua"}},{"cell_type":"markdown","source":["The objective of this project was to predict the closing price of Yes Bank stock using historical data, including the date, open, high, and low prices. We transformed the Date column into numeric features to capture potential trends and used Open, High, Low, Day, Month as predictors. Starting with a Linear Regression baseline, we shifted to a Random Forest Regressor to capture non-linear patterns in stock prices. Using hyperparameter tuning with RandomizedSearchCV, GridSearchCV, and Bayesian Optimization, we refined the model for better accuracy, with the Random Forest model achieving lower error rates. The final model demonstrated the potential to support short-term stock price predictions, helping analysts and investors anticipate changes and make informed trading decisions. Although effective, the model could further improve by integrating external factors like news and market sentiment. Overall, this project highlights the value of data preparation, model selection, and optimization in building predictive financial models, showing potential for expanded applications in investment and portfolio management."],"metadata":{"id":"F6v_1wHtG2nS"}},{"cell_type":"markdown","source":["# **GitHub Link -**"],"metadata":{"id":"w6K7xa23Elo4"}},{"cell_type":"markdown","source":["Provide your GitHub Link here."],"metadata":{"id":"h1o69JH3Eqqn"}},{"cell_type":"markdown","source":["# **Problem Statement**\n"],"metadata":{"id":"yQaldy8SH6Dl"}},{"cell_type":"markdown","source":["1. Predictive Analysis of Stock Prices: Develop a machine learning model to predict the closing price of Yes Bank stock based on historical data, including open, high, and low prices. This predictive capability aims to support financial analysts in making data-driven trading decisions.\n","\n","2. Optimization of Model Accuracy for Financial Forecasting: Investigate and apply hyperparameter optimization techniques, such as GridSearchCV, RandomizedSearchCV, and Bayesian Optimization, to improve model accuracy in forecasting stock prices. The objective is to identify optimal model parameters that minimize prediction errors and maximize reliability.\n","\n","3. Feature Engineering to Enhance Predictive Power: Examine and transform the Date feature into relevant numeric variables (day, month, and year) to capture seasonal or time-based patterns in stock prices. The goal is to test whether these engineered features improve the model’s ability to predict stock price trends effectively.\n","\n","4. Evaluating Predictive Model Performance with Financial Data: Evaluate the effectiveness of regression models for predicting stock prices using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). This problem focuses on assessing the accuracy and stability of predictions and determining the model’s suitability for real-world financial forecasting applications."],"metadata":{"id":"DpeJGUA3kjGy"}},{"cell_type":"markdown","source":["# **General Guidelines** : -  "],"metadata":{"id":"mDgbUHAGgjLW"}},{"cell_type":"markdown","source":["1.   Well-structured, formatted, and commented code is required.\n","2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n","     \n","     The additional credits will have advantages over other students during Star Student selection.\n","       \n","             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n","                       without a single error logged. ]\n","\n","3.   Each and every logic should have proper comments.\n","4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n","        \n","\n","```\n","# Chart visualization code\n","```\n","            \n","\n","*   Why did you pick the specific chart?\n","*   What is/are the insight(s) found from the chart?\n","* Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason.\n","\n","5. You have to create at least 15 logical & meaningful charts having important insights.\n","\n","\n","[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n","\n","U - Univariate Analysis,\n","\n","B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n","\n","M - Multivariate Analysis\n"," ]\n","\n","\n","\n","\n","\n","6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n","\n","\n","*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n","\n","\n","*   Cross- Validation & Hyperparameter Tuning\n","\n","*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n","\n","*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"],"metadata":{"id":"ZrxVaUj-hHfC"}},{"cell_type":"markdown","source":["# ***Let's Begin !***"],"metadata":{"id":"O_i_v8NEhb9l"}},{"cell_type":"markdown","source":["## ***1. Know Your Data***"],"metadata":{"id":"HhfV-JJviCcP"}},{"cell_type":"markdown","source":["### Import Libraries"],"metadata":{"id":"Y3lxredqlCYt"}},{"cell_type":"code","source":["# Import Librarie\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from scipy import stats\n"],"metadata":{"id":"M8Vqi-pPk-HR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Loading"],"metadata":{"id":"3RnN4peoiCZX"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"4CkvbW_SlZ_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# loading dataset\n","df= pd.read_csv('/content/drive/MyDrive/data_YesBank_StockPrices.csv')\n","df.head(6)"],"metadata":{"id":"88i1nIJEfCcg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset First View"],"metadata":{"id":"x71ZqKXriCWQ"}},{"cell_type":"code","source":["# Dataset First Look\n","df.head(6)"],"metadata":{"id":"LWNFOSvLl09H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Rows & Columns count"],"metadata":{"id":"7hBIi_osiCS2"}},{"cell_type":"code","source":["# Dataset Rows & Columns count\n","print(df.columns)\n","df.shape\n"],"metadata":{"id":"Kllu7SJgmLij"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Dataset Information"],"metadata":{"id":"JlHwYmJAmNHm"}},{"cell_type":"code","source":["# Dataset Info\n","df.info()"],"metadata":{"id":"e9hRXRi6meOf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Duplicate Values"],"metadata":{"id":"35m5QtbWiB9F"}},{"cell_type":"code","source":["# Dataset Duplicate Value Count\n","df.duplicated().sum()"],"metadata":{"id":"1sLdpKYkmox0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Missing Values/Null Values"],"metadata":{"id":"PoPl-ycgm1ru"}},{"cell_type":"code","source":["# Missing Values/Null Values Count\n","df.isna().sum()"],"metadata":{"id":"GgHWkxvamxVg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What did you know about your dataset?"],"metadata":{"id":"H0kj-8xxnORC"}},{"cell_type":"markdown","source":["In my dataset, there are 185 rows and 5 columns. There are no duplicate values and there are no missing values.\n"],"metadata":{"id":"gfoNAAC-nUe_"}},{"cell_type":"markdown","source":["## ***2. Understanding Your Variables***"],"metadata":{"id":"nA9Y7ga8ng1Z"}},{"cell_type":"code","source":["# Dataset Columns\n","df.columns"],"metadata":{"id":"j7xfkqrt5Ag5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset Describe\n","df.describe()"],"metadata":{"id":"DnOaZdaE5Q5t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variables Description"],"metadata":{"id":"PBTbrJXOngz2"}},{"cell_type":"markdown","source":["Here we have 5 columns (Date, Open, High, Low, Close).\n","Date: Opening date\n","Open: Opening Price\n","High: Highest Price in the Day\n","Low: Lowest Price in the Day\n","Close: Closing Price"],"metadata":{"id":"aJV4KIxSnxay"}},{"cell_type":"markdown","source":["### Check Unique Values for each variable."],"metadata":{"id":"u3PMJOP6ngxN"}},{"cell_type":"code","source":["# Check Unique Values for each variable.\n","df.nunique()"],"metadata":{"id":"zms12Yq5n-jE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 3. ***Data Wrangling***"],"metadata":{"id":"dauF4eBmngu3"}},{"cell_type":"markdown","source":["### Data Wrangling Code"],"metadata":{"id":"bKJF3rekwFvQ"}},{"cell_type":"code","source":["# Write your code to make your dataset analysis ready.\n","# converting the Date column from object to datetime\n","df['Date']=pd.to_datetime(df['Date'],format='%b-%y')\n","# adding new colum for daily return\n","df['daily_return'] = df['Close'].pct_change()\n"],"metadata":{"id":"wk-9a2fpoLcV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### What all manipulations have you done and insights you found?"],"metadata":{"id":"MSa1f5Uengrz"}},{"cell_type":"markdown","source":["First I convert my Date column from object type to dattime type. Then I add new column named 'daily_return'. Since there are no null values or missing values so theres no need to remove them."],"metadata":{"id":"LbyXE7I1olp8"}},{"cell_type":"markdown","source":["## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"],"metadata":{"id":"GF8Ens_Soomf"}},{"cell_type":"markdown","source":["#### Chart - 1"],"metadata":{"id":"0wOQAZs5pc--"}},{"cell_type":"code","source":["# Chart - 1 visualization code\n","plt.plot(df['Close'], label='Close Price', color='blue')\n","plt.title('Yes Bank Closing Prices Over Time')\n","plt.ylabel('Price')\n","plt.legend()\n","plt.grid()\n","plt.show()"],"metadata":{"id":"7v_ESjsspbW7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"K5QZ13OEpz2H"}},{"cell_type":"markdown","source":[" To show trends over time."],"metadata":{"id":"XESiWehPqBRc"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"lQ7QKXXCp7Bj"}},{"cell_type":"markdown","source":[" This chart allows us to see trends in the closing price over time, such as periods of increase or decrease."],"metadata":{"id":"C_j1G7yiqdRP"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"448CDAPjqfQr"}},{"cell_type":"markdown","source":["Helps in forecasting future prices based on historical trends."],"metadata":{"id":"3cspy4FjqxJW"}},{"cell_type":"markdown","source":["#### Chart - 2"],"metadata":{"id":"KSlN3yHqYklG"}},{"cell_type":"code","source":["# Chart - 2 visualization code\n","plt.scatter(df['Open'], df['Close'], color='green')\n","plt.title('Relationship Between Open and Close Prices')\n","plt.xlabel('Open Price')\n","plt.ylabel('Close Price')\n","plt.grid()\n","plt.show()"],"metadata":{"id":"R4YgtaqtYklH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"t6dVpIINYklI"}},{"cell_type":"markdown","source":["To explore the relationship between two continuous variables."],"metadata":{"id":"5aaW0BYyYklI"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"ijmpgYnKYklI"}},{"cell_type":"markdown","source":["This chart helps to visualize any correlation between the opening and closing prices, revealing trends in market behavior."],"metadata":{"id":"PSx9atu2YklI"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"-JiQyfWJYklI"}},{"cell_type":"markdown","source":["Helps traders understand how opening prices affect closing prices."],"metadata":{"id":"BcBbebzrYklV"}},{"cell_type":"markdown","source":["#### Chart - 3"],"metadata":{"id":"EM7whBJCYoAo"}},{"cell_type":"code","source":["# Chart - 3 visualization code\n","# Bar chart for High and Low prices\n","plt.figure(figsize=(10, 5))\n","bar_width = 0.35\n","index = range(len(df))\n","\n","plt.bar(index, df['High'], width=bar_width, label='High', color='green', alpha=0.6)\n","plt.bar([i + bar_width for i in index], df['Low'], width=bar_width, label='Low', color='red', alpha=0.6)\n","\n","plt.title('High and Low Prices Over Time')\n","plt.xlabel('Date')\n","plt.ylabel('Price')\n","# plt.xticks([i + bar_width / 2 for i in index], df.index.date, rotation=45)\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"t6GMdE67YoAp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### 1. Why did you pick the specific chart?"],"metadata":{"id":"fge-S5ZAYoAp"}},{"cell_type":"markdown","source":["To compare high and low prices over a specific period."],"metadata":{"id":"5dBItgRVYoAp"}},{"cell_type":"markdown","source":["##### 2. What is/are the insight(s) found from the chart?"],"metadata":{"id":"85gYPyotYoAp"}},{"cell_type":"markdown","source":["This chart helps to visualize the daily price range, showing the volatility and extreme price points."],"metadata":{"id":"4jstXR6OYoAp"}},{"cell_type":"markdown","source":["##### 3. Will the gained insights help creating a positive business impact?\n","Are there any insights that lead to negative growth? Justify with specific reason."],"metadata":{"id":"RoGjAbkUYoAp"}},{"cell_type":"markdown","source":["Assists in understanding price volatility, helping to manage risk."],"metadata":{"id":"zfJ8IqMcYoAp"}},{"cell_type":"markdown","source":["## ***5. Hypothesis Testing***"],"metadata":{"id":"g-ATYxFrGrvw"}},{"cell_type":"markdown","source":["### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."],"metadata":{"id":"Yfr_Vlr8HBkt"}},{"cell_type":"markdown","source":["Answer Here."],"metadata":{"id":"-7MS06SUHkB-"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 1"],"metadata":{"id":"8yEUt7NnHlrM"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"tEA2Xm5dHt1r"}},{"cell_type":"markdown","source":["\n","\n","*   Null Hypothesis (H0): The average closing price in the second half of the year is equal to the average closing price in the first half.\n","*  Alternative Hypothesis (H1): The average closing price in the second half of the year is greater than in the first half.\n","\n","\n","\n","\n","\n"],"metadata":{"id":"HI9ZP0laH0D-"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"I79__PHVH19G"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","t_statistic, p_value = stats.ttest_rel(df['Open'], df['Close'])\n","\n","print(f\"T-Statistic: {t_statistic}\")\n","print(f\"P-Value: {p_value}\")\n","\n","# Interpret the p-value\n","alpha = 0.05  # Significance level\n","if p_value < alpha:\n","    print(\"Reject the null hypothesis: There is a significant difference between Open and Close prices.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: There is no significant difference between Open and Close prices.\")"],"metadata":{"id":"oZrfquKtyian"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"Ou-I18pAyIpj"}},{"cell_type":"markdown","source":["Paired t-test"],"metadata":{"id":"s2U0kk00ygSB"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"fF3858GYyt-u"}},{"cell_type":"markdown","source":[" For comparing Open and Close prices is based on several factors"],"metadata":{"id":"HO4K0gP5y3B4"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 2"],"metadata":{"id":"4_0_7-oCpUZd"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"hwyV_J3ipUZe"}},{"cell_type":"markdown","source":["\n","\n","*  Null Hypothesis (H0) There is no significant difference between the High and Low prices of the stock.\n","*   Alternative Hypothesis (H1) There is a significant difference between the High and Low prices of the stock.\n","\n"],"metadata":{"id":"FnpLGJ-4pUZe"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"3yB-zSqbpUZe"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","t_statistic_high_low, p_value_high_low = stats.ttest_rel(df['High'], df['Low'])\n","\n","print(\"Scenario 1: Paired T-Test between High and Low Prices\")\n","print(f\"T-Statistic: {t_statistic_high_low}\")\n","print(f\"P-Value: {p_value_high_low}\")\n","\n","# Interpret the p-value for High and Low Prices\n","alpha = 0.05  # Significance level\n","if p_value_high_low < alpha:\n","    print(\"Reject the null hypothesis: There is a significant difference between High and Low prices.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: There is no significant difference between High and Low prices.\")\n","\n","# --- Scenario 2: One-Sample T-Test for Close Prices ---\n","# Test if mean Close price is greater than $100\n","t_statistic_close, p_value_close = stats.ttest_1samp(df['Close'], 100)\n","\n","# Since this is a one-tailed test, we need to divide the p-value by 2\n","p_value_close_one_tailed = p_value_close / 2\n","\n","print(\"\\nScenario 2: One-Sample T-Test for Close Prices\")\n","print(f\"T-Statistic: {t_statistic_close}\")\n","print(f\"P-Value (One-Tailed): {p_value_close_one_tailed}\")\n","\n","# Interpret the p-value for Close Prices\n","if p_value_close_one_tailed < alpha:\n","    print(\"Reject the null hypothesis: The average Close price is greater than $100.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: The average Close price is not greater than $100.\")"],"metadata":{"id":"sWxdNTXNpUZe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"dEUvejAfpUZe"}},{"cell_type":"markdown","source":["Paired t-test and One Sample t-test."],"metadata":{"id":"oLDrPz7HpUZf"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"Fd15vwWVpUZf"}},{"cell_type":"markdown","source":["Both tests were selected based on the nature of the data and the specific hypotheses being tested. The paired t-test was suitable for comparing two related samples, while the one-sample t-test was used for comparing a sample mean to a known value."],"metadata":{"id":"4xOGYyiBpUZf"}},{"cell_type":"markdown","source":["### Hypothetical Statement - 3"],"metadata":{"id":"bn_IUdTipZyH"}},{"cell_type":"markdown","source":["#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."],"metadata":{"id":"49K5P_iCpZyH"}},{"cell_type":"markdown","source":["*   Null Hypothesis (H0) The average Open price of the stock is equal to $50.\n","*   Alternative Hypothesis (H1) The average Open price of the stock is not equal to $50.\n","\n"],"metadata":{"id":"7gWI5rT9pZyH"}},{"cell_type":"markdown","source":["#### 2. Perform an appropriate statistical test."],"metadata":{"id":"Nff-vKELpZyI"}},{"cell_type":"code","source":["# Perform Statistical Test to obtain P-Value\n","t_statistic_open, p_value_open = stats.ttest_1samp(df['Open'], 50)\n","\n","# Print the results\n","print(\"One-Sample T-Test for Open Prices\")\n","print(f\"T-Statistic: {t_statistic_open}\")\n","print(f\"P-Value: {p_value_open}\")\n","\n","# Since this is a two-tailed test, we do not need to adjust the p-value\n","alpha = 0.05  # Significance level\n","if p_value_open < alpha:\n","    print(\"Reject the null hypothesis: The average Open price is not equal to $50.\")\n","else:\n","    print(\"Fail to reject the null hypothesis: The average Open price is equal to $50.\")"],"metadata":{"id":"s6AnJQjtpZyI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which statistical test have you done to obtain P-Value?"],"metadata":{"id":"kLW572S8pZyI"}},{"cell_type":"markdown","source":["One sample t-test"],"metadata":{"id":"ytWJ8v15pZyI"}},{"cell_type":"markdown","source":["##### Why did you choose the specific statistical test?"],"metadata":{"id":"dWbDXHzopZyI"}},{"cell_type":"markdown","source":["The hypothesis involves comparing the mean of a single sample (the Open prices) against a specific known value (in this case, $50). The one-sample t-test is designed for exactly this type of analysis."],"metadata":{"id":"M99G98V6pZyI"}},{"cell_type":"markdown","source":["## ***6. Feature Engineering & Data Pre-processing***"],"metadata":{"id":"yLjJCtPM0KBk"}},{"cell_type":"markdown","source":["### 1. Handling Missing Values"],"metadata":{"id":"xiyOF9F70UgQ"}},{"cell_type":"code","source":["# Handling Missing Values & Missing Value Imputation\n","df.isna().sum()"],"metadata":{"id":"iRsAHk1K0fpS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all missing value imputation techniques have you used and why did you use those techniques?"],"metadata":{"id":"7wuGOrhz0itI"}},{"cell_type":"markdown","source":["Since there are no missing values so there's no need to handling them."],"metadata":{"id":"1ixusLtI0pqI"}},{"cell_type":"markdown","source":["### 2. Handling Outliers"],"metadata":{"id":"id1riN9m0vUs"}},{"cell_type":"code","source":["# Handling Outliers & Outlier treatments\n","Q1 = df['Open'].quantile(0.25)\n","Q3 = df['Open'].quantile(0.75)\n","IQR = Q3 - Q1\n","\n","# Define the bounds for outliers\n","lower_bound = Q1 - 1.5 * IQR\n","upper_bound = Q3 + 1.5 * IQR\n","\n","# Identify outliers\n","outliers = df[(df['Open'] < lower_bound) | (df['Open'] > upper_bound)]\n","print(outliers)\n","\n","# treating outliers\n","df['Open'] = np.where(df['Open'] < lower_bound, lower_bound, df['Open'])\n","df['Open'] = np.where(df['Open'] > upper_bound, upper_bound, df['Open'])\n","print(\"Data after handling outliers:\\n\", df.describe())\n"],"metadata":{"id":"M6w2CzZf04JK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### What all outlier treatment techniques have you used and why did you use those techniques?"],"metadata":{"id":"578E2V7j08f6"}},{"cell_type":"markdown","source":["I use Capping technique to handle outliers. I choose this because Capping allows you to retain all observations in the dataset, which is especially important in cases where losing data might lead to loss of valuable information or insights."],"metadata":{"id":"uGZz5OrT1HH-"}},{"cell_type":"markdown","source":["### 3. Categorical Encoding"],"metadata":{"id":"89xtkJwZ18nB"}},{"cell_type":"code","source":["# Encode your categorical columns\n","categorical_columns = df.select_dtypes(include=['object', 'category']).columns\n","\n","# Display the categorical columns\n","print(\"Categorical Columns:\\n\", categorical_columns)"],"metadata":{"id":"21JmIYMG2hEo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### What all categorical encoding techniques have you used & why did you use those techniques?"],"metadata":{"id":"67NQN5KX2AMe"}},{"cell_type":"markdown","source":["We dont have any categorical column in our dataset.\n"],"metadata":{"id":"UDaue5h32n_G"}},{"cell_type":"markdown","source":["## ***7. ML Model Implementation***"],"metadata":{"id":"VfCC591jGiD4"}},{"cell_type":"markdown","source":["### ML Model - 1"],"metadata":{"id":"OB4l2ZhMeS1U"}},{"cell_type":"code","source":["# ML Model - 1 Implementation\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","\n","df['Day']=df['Date'].dt.day\n","df['Month']=df['Date'].dt.month\n","\n","X = df[['Open', 'High', 'Low', 'Day', 'Month']]\n","y = df['Close']\n","X_train,X_test,y_train,y_test= train_test_split(X,y,test_size=0.2,random_state=42)\n","\n","# Fit the Algorithm\n","model =LinearRegression()\n","model.fit(X_train,y_train)\n","\n","# Predict on the model\n","pred= model.predict(X_test)"],"metadata":{"id":"7ebyywQieS1U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."],"metadata":{"id":"ArJBuiUVfxKd"}},{"cell_type":"code","source":["# Visualizing evaluation Metric Score chart\n","mae = mean_absolute_error(y_test, pred)\n","mse = mean_squared_error(y_test, pred)\n","rmse = np.sqrt(mse)\n","\n","print(\"Mean Absolute Error (MAE):\", mae)\n","print(\"Mean Squared Error (MSE):\", mse)\n","print(\"Root Mean Squared Error (RMSE):\", rmse)"],"metadata":{"id":"rqD5ZohzfxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["I used Linear Regression model in this dataset. To train and test the data I used the train_test split module. Then I evaluate the result using MSE, MAE, RMSE."],"metadata":{"id":"B-d2cdJEr2Dd"}},{"cell_type":"markdown","source":["#### 2. Cross- Validation & Hyperparameter Tuning"],"metadata":{"id":"4qY1EAkEfxKe"}},{"cell_type":"code","source":["# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n","from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","from scipy.stats import randint\n","\n","# Fit the Algorithm\n","model = RandomForestRegressor(random_state=42)\n","random_grid = {\n","    'n_estimators': randint(50, 200),\n","    'max_depth': randint(3, 20),\n","    'min_samples_split': randint(2, 10),\n","    'min_samples_leaf': randint(1, 4)\n","}\n","grid_grid = {\n","    'n_estimators': [100, 150, 200],\n","    'max_depth': [10, 15, 20],\n","    'min_samples_split': [2, 5, 10],\n","    'min_samples_leaf': [1, 2, 4]\n","}\n","# 1. RandomizedSearchCV for hyperparameter tuning\n","random_search = RandomizedSearchCV(estimator=model, param_distributions=random_grid, n_iter=10, cv=3, random_state=42, n_jobs=-1)\n","random_search.fit(X_train, y_train)\n","\n","# Best parameters from RandomizedSearchCV\n","print(\"Best parameters from RandomizedSearchCV:\", random_search.best_params_)\n","\n","# 2. GridSearchCV for hyperparameter tuning\n","grid_search = GridSearchCV(estimator=model, param_grid=grid_grid,\n","                           cv=3, n_jobs=-1)\n","grid_search.fit(X_train, y_train)\n","\n","# Best parameters from GridSearchCV\n","print(\"Best parameters from GridSearchCV:\", grid_search.best_params_)\n"],"metadata":{"id":"Dy61ujd6fxKe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Which hyperparameter optimization technique have you used and why?"],"metadata":{"id":"PiV4Ypx8fxKe"}},{"cell_type":"markdown","source":["I used RandomizedSearchCV and GridSearcgCV. Beacause RandomizedSearchCV randomly searches combinations of hyperparameters within the defined ranges and GridSearchCV searches all possible combinations in the grid."],"metadata":{"id":"negyGRa7fxKf"}},{"cell_type":"markdown","source":["# **Conclusion**"],"metadata":{"id":"gCX9965dhzqZ"}},{"cell_type":"markdown","source":["In this project, we developed and evaluated a machine learning model to predict the closing price of Yes Bank stock using a variety of techniques, from initial data wrangling and feature engineering to model training, hyperparameter optimization, and evaluation.Through systematic data processing, model selection, and optimization, we achieved a model that can reasonably predict stock prices. While the model is valuable as an exploratory tool, additional external data sources and complex algorithms could yield even higher accuracy. This project highlights the importance of feature engineering, model selection, and hyperparameter tuning in building effective predictive models for financial data. With further development, this predictive capability could be a significant asset for portfolio management and stock trading strategies."],"metadata":{"id":"Fjb1IsQkh3yE"}},{"cell_type":"markdown","source":["### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"],"metadata":{"id":"gIfDvo9L0UH2"}}]}